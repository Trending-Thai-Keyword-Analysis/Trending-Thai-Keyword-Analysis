{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning & Split Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MqosM1DocQ6s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from datetime import datetime,timedelta\n",
        "from pytz import timezone\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Or1_f9GsswUX"
      },
      "outputs": [],
      "source": [
        "all_agent = [\n",
        "    'ThaiPublica',\n",
        "    'PracharChat',\n",
        "    'Sanook',\n",
        "    'Manager',\n",
        "    'NaewNa',\n",
        "    'Matichon',\n",
        "    'VoaThai',\n",
        "    'BangkokToday',\n",
        "    'Infoquest',\n",
        "    'PrachaTai',\n",
        "    'SiamBlockchain',\n",
        "    'PostToday',\n",
        "    'ThaiRath'\n",
        "]\n",
        "\n",
        "'''\n",
        "Thaiware\n",
        "ThaiPBS\n",
        "Mono29\n",
        "Mcot\n",
        "KhaoSod\n",
        "Investing\n",
        "Goethe\n",
        "'''\n",
        "\n",
        "clean_path = '../assets/CleanedData'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GJUSNcF3N1cN"
      },
      "outputs": [],
      "source": [
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory. ' +  directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "vw6fK1JBqr-a"
      },
      "outputs": [],
      "source": [
        "def html_parser(news):    \n",
        "    temp =  bs(str(news),'html.parser').get_text()\n",
        "    result = ' '.join(temp.split())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "SogKIyhgmqrP"
      },
      "outputs": [],
      "source": [
        "def local_time(time):\n",
        "    date = []\n",
        "    if time[-1] == 'T':\n",
        "        date = datetime.strptime(time,'%a, %d %b %Y %H:%M:%S %Z')\n",
        "        date = date.astimezone(timezone('Asia/Bangkok'))\n",
        "    elif time[-3] == ':' and time[-6] == ' ':\n",
        "        date = datetime.strptime(time,'%B %d, %Y %H:%M')\n",
        "    elif time[-3] == ':':\n",
        "        date = datetime.strptime(time,'%Y-%m-%d %H:%M:%S')\n",
        "    else:\n",
        "        date = datetime.strptime(time,'%a, %d %b %Y %H:%M:%S %z')\n",
        "        date = date.astimezone(timezone('Asia/Bangkok'))\n",
        "    return date.strftime('%Y_%m_%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8yLAqPc3no20"
      },
      "outputs": [],
      "source": [
        "def clean_csv(df_news):\n",
        "  temp = df_news\n",
        "  temp['summary'] = temp['summary'].apply(html_parser)\n",
        "  temp['published'] = temp['published'].apply(local_time)\n",
        "  result = temp.drop_duplicates(subset=['summary'])\n",
        "  result = result.reset_index(drop=True)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xilxL7CVqliU"
      },
      "outputs": [],
      "source": [
        "def split_time(df_news,agent):\n",
        "  temp = df_news\n",
        "  time = df_news['published'].unique()\n",
        "  for i in time:\n",
        "    data = df_news[df_news['published'] == i]\n",
        "    data.reset_index(drop=True,inplace=True)\n",
        "    createFolder('../assets/CleanedData/'+agent)\n",
        "    data.to_csv('../assets/CleanedData/'+agent+'/'+i+'.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "OOih_3frKqWl"
      },
      "outputs": [],
      "source": [
        "def to_csv(agent):\n",
        "  for i in agent:\n",
        "    print('Process : '+i)\n",
        "    df_news = pd.read_csv('../assets/Data/'+i+'.csv')\n",
        "    temp = clean_csv(df_news)\n",
        "    split_time(temp,i)\n",
        "    print('==========')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5EBc8qPFlqb",
        "outputId": "60df504a-3d3a-44de-af79-d7a5696f9f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process : ThaiPublica\n",
            "==========\n",
            "Process : PracharChat\n",
            "==========\n",
            "Process : Sanook\n",
            "==========\n",
            "Process : Manager\n",
            "==========\n",
            "Process : NaewNa\n",
            "==========\n",
            "Process : Matichon\n",
            "==========\n",
            "Process : VoaThai\n",
            "==========\n",
            "Process : BangkokToday\n",
            "==========\n",
            "Process : Infoquest\n",
            "==========\n",
            "Process : PrachaTai\n",
            "==========\n",
            "Process : SiamBlockchain\n",
            "==========\n",
            "Process : PostToday\n",
            "==========\n",
            "Process : ThaiRath\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "to_csv(all_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def splitDate(data_path,news_agent):\n",
        "    path = '../assets/SplitData'\n",
        "    createFolder('../assets/SplitData')\n",
        "\n",
        "    ## Loop for all Agent News\n",
        "    for agent in news_agent:\n",
        "        all_date = os.listdir(data_path+'/'+agent)\n",
        "        for f in all_date:\n",
        "\n",
        "            ## Create If dont have file\n",
        "            if not os.path.isfile(path+'/'+f):\n",
        "\n",
        "                create = pd.DataFrame([],columns=['title','summary','link','published'])\n",
        "                create.to_csv(path+'/'+f,index=False)\n",
        "\n",
        "            ## Concat\n",
        "            df1 = pd.read_csv(path+'/'+f)\n",
        "            df2 = pd.read_csv(data_path+'/'+agent+'/'+f)\n",
        "            result = df1.append(df2,ignore_index=False)\n",
        "            result.to_csv(path+'/'+f,index=False)\n",
        "\n",
        "        # print(all_date)\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "splitDate(clean_path,all_agent)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CleanRss",
      "provenance": []
    },
    "interpreter": {
      "hash": "79e31fca8912b52a24e38fd1bb3098dbc875f72cd4b82e079863a26457044337"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
